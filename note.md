- coco_subset_5k
    - **预训练（0 训练）**：AP = **0.519**
    - **跑完训练后**：AP = **0.542**
    - **提升**：+**0.023 AP**（相对提升约 **4.4%**，0.023/0.519）

- **BERT 侧在 COCO 类别检测里对“分类/对齐”贡献很大**
- 冻结它几乎没带来明显加速，却带来很大性能损失
    - Baseline（10k/1k，5 epoch，AMP）：AP=**0.550**，Training time=3:07:14
    - Freeze-BERT-lr0（10k/1k，5 epoch，AMP）：AP=**0.454**，Training time=2:53:43
    - 冻结文本编码器会显著降低性能（-0.096 AP），加速收益有限（~7%），因此后续改进不采用该策略。